{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PARAMS = yaml.load(open(\"configs/dataset.yaml\"), Loader=yaml.SafeLoader)\n",
    "PREPROCESSING_PARAMS = yaml.load(open(\"configs/preprocessing.yaml\"), Loader=yaml.SafeLoader)\n",
    "MODEL_NAME = yaml.load(open(\"configs/model.yaml\"), Loader=yaml.SafeLoader)['MODEL_NAME']\n",
    "MODEL_PARAMS = yaml.load(open(\"configs/model.yaml\"), Loader=yaml.SafeLoader)[MODEL_NAME]\n",
    "TRAINING_PARAMS = yaml.load(open(\"configs/training.yaml\"), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =  DATASET_PARAMS['CATEGORIES']\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, DATASET_PARAMS['DATA_PATH'])\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATASET_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_device\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import generate_filenames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames_df = generate_filenames_df(TRAIN_DIR, categories)\n",
    "val_filenames_df = generate_filenames_df(VAL_DIR, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import preprocess\n",
    "\n",
    "target_input_size = tuple(PREPROCESSING_PARAMS['INPUT_SIZE'])\n",
    "train_transform = preprocess(\n",
    "    target_input_size=target_input_size,\n",
    "    rotation_range=PREPROCESSING_PARAMS['ROTATION_RANGE'],\n",
    "    width_shift_range=PREPROCESSING_PARAMS['WIDTH_SHIFT_RANGE'],\n",
    "    height_shift_range=PREPROCESSING_PARAMS['HEIGHT_SHIFT_RANGE'],\n",
    "    brightness_range=PREPROCESSING_PARAMS['BRIGHTNESS_RANGE'],\n",
    "    zoom_range=PREPROCESSING_PARAMS['ZOOM_RANGE'],\n",
    "    horizontal_flip=PREPROCESSING_PARAMS['HORIZONTAL_FLIP'],\n",
    "    vertical_flip=PREPROCESSING_PARAMS['VERTICAL_FLIP'],\n",
    "    channel_shift_range=PREPROCESSING_PARAMS['CHANNEL_SHIFT_RANGE'],\n",
    "    fill_mode=PREPROCESSING_PARAMS['FILL_MODE'],\n",
    "    shear_range=PREPROCESSING_PARAMS['SHEAR_RANGE']\n",
    "    )\n",
    "\n",
    "val_transform = preprocess(target_input_size=target_input_size) # only rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import Loader\n",
    "train_loader = Loader(train_filenames_df, \n",
    "                     batch_size=TRAINING_PARAMS['BATCH_SIZE'], \n",
    "                     num_workers=TRAINING_PARAMS['NUM_WORKERS'], \n",
    "                     transform=train_transform, \n",
    "                     shuffle=TRAINING_PARAMS['SHUFFLE'])\n",
    "\n",
    "val_loader = Loader(val_filenames_df, \n",
    "                    batch_size=TRAINING_PARAMS['BATCH_SIZE'], \n",
    "                    num_workers=TRAINING_PARAMS['NUM_WORKERS'], \n",
    "                    transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientCapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"CAPSNET\":\n",
    "    from src.model import EfficientCapsNet\n",
    "    from src.loss import MarginLoss, marginLoss\n",
    "\n",
    "    model = EfficientCapsNet(input_size=(MODEL_PARAMS['INPUT_SIZE']))\n",
    "    loss = MarginLoss()\n",
    "    # loss = marginLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"DENSENET121\":\n",
    "    from src.densenet import DenseNet121\n",
    "    from torch.nn import CrossEntropyLoss\n",
    "\n",
    "    model = DenseNet121(num_classes=num_classes, dropout_rate=MODEL_PARAMS['DROPOUT_RATE'])\n",
    "    loss = CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=TRAINING_PARAMS['LEARNING_RATE'])\n",
    "\n",
    "# use torcheval metrics\n",
    "# metrics\n",
    "from torcheval.metrics import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassAUROC,\n",
    "    MulticlassAUPRC,\n",
    "    MulticlassRecall\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from src.metrics import (\n",
    "    MulticlassMCC,\n",
    "    MulticlassSpecificity\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"mcc\": MulticlassMCC(num_classes=num_classes, device=DEVICE),\n",
    "    \"auprc\": MulticlassAUPRC(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"auroc\": MulticlassAUROC(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"f1_score\": MulticlassF1Score(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"precision\": MulticlassPrecision(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE),\n",
    "    \"recall\": MulticlassRecall(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE),\n",
    "    \"specificity\": MulticlassSpecificity(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Epoch 1/10\n",
      "Initial input x - min: 0.0000, max: 1.0000, mean: 0.6801, shape: torch.Size([32, 3, 299, 299])\n",
      "--- Checking conv1 and bn1 parameters ---\n",
      "conv1.weight - min: -0.5720, max: 0.4857, mean: 0.0031, shape: torch.Size([32, 3, 5, 5])\n",
      "conv1.bias - min: -0.1135, max: 0.1042, mean: -0.0061, shape: torch.Size([32])\n",
      "bn1.weight - min: 1.0000, max: 1.0000, mean: 1.0000, shape: torch.Size([32])\n",
      "bn1.bias - min: 0.0000, max: 0.0000, mean: 0.0000, shape: torch.Size([32])\n",
      "bn1.running_mean - min: 0.0000, max: 0.0000, mean: 0.0000, shape: torch.Size([32])\n",
      "bn1.running_var - min: 1.0000, max: 1.0000, mean: 1.0000, shape: torch.Size([32])\n",
      "--- End of conv1 and bn1 parameters ---\n",
      "x after conv1 - min: -4.2991, max: 4.6843, mean: 0.1551, shape: torch.Size([32, 32, 295, 295])\n",
      "x after bn1 (before relu) - min: -15.8815, max: 16.5468, mean: 0.0000, shape: torch.Size([32, 32, 295, 295])\n",
      "x after conv1 + bn1 + relu - min: 0.0000, max: 16.5468, mean: 0.4106, shape: torch.Size([32, 32, 295, 295])\n",
      "x after conv2 + bn2 + relu - min: 0.0000, max: 20.7794, mean: 0.3508, shape: torch.Size([32, 64, 293, 293])\n",
      "x after conv3 + bn3 + relu - min: 0.0000, max: 22.0025, mean: 0.2873, shape: torch.Size([32, 64, 291, 291])\n",
      "x after conv4 + bn4 + relu (input to primary_caps) - min: 0.0000, max: 21.5994, mean: 0.2582, shape: torch.Size([32, 128, 145, 145])\n",
      "x after primary_caps - min: -0.5453, max: 0.5556, mean: -0.0004, shape: torch.Size([32, 128, 64])\n",
      "x after routing_caps (input to len_final_caps) - min: -0.0483, max: 0.0424, mean: -0.0003, shape: torch.Size([32, 3, 16])\n",
      "y_predict (final model output) - min: 0.0352, max: 0.0769, mean: 0.0556, shape: torch.Size([32, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNUM_EPOCHS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRINT_EVERY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAVE_PATIENCE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAVE_PATH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAVE_MODEL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAINING_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSAVE_METRICS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yuno\\Documents\\Kuliah Sarjana\\Project\\XDL_Collitis\\src\\train.py:71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, metrics, print_every, save_patience, save_path, save_model, save_metrics)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!! NaN or Inf detected in model_outputs_raw !!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_outputs_raw)\n\u001b[1;32m---> 71\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_outputs_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(loss)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!! NaN or Inf detected in loss !!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yuno\\anaconda3\\envs\\xdl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yuno\\anaconda3\\envs\\xdl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Yuno\\Documents\\Kuliah Sarjana\\Project\\XDL_Collitis\\src\\loss.py:43\u001b[0m, in \u001b[0;36mMarginLoss.forward\u001b[1;34m(self, target, input)\u001b[0m\n\u001b[0;32m     36\u001b[0m     digit_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Convert target to one-hot encoding if needed\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# if len(target.shape) == 1:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#     target = torch.nn.functional.one_hot(target, num_classes=3)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m present_losses \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_min\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdigit_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m absent_losses \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp_min(\n\u001b[0;32m     46\u001b[0m     digit_probs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_neg, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     47\u001b[0m ) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     48\u001b[0m losses \u001b[38;5;241m=\u001b[39m present_losses \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_ \u001b[38;5;241m*\u001b[39m absent_losses\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from src.train import train\n",
    "\n",
    "history = train(model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    criterion=loss, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=TRAINING_PARAMS['NUM_EPOCHS'], \n",
    "    device=DEVICE,\n",
    "    metrics=metrics,\n",
    "    print_every=TRAINING_PARAMS['PRINT_EVERY'],\n",
    "    save_patience=TRAINING_PARAMS['SAVE_PATIENCE'],\n",
    "    save_path=TRAINING_PARAMS['SAVE_PATH'],\n",
    "    save_model=TRAINING_PARAMS['SAVE_MODEL'],\n",
    "    save_metrics=TRAINING_PARAMS['SAVE_METRICS']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xdl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
