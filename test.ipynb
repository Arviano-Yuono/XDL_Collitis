{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PARAMS = yaml.load(open(\"configs/dataset.yaml\"), Loader=yaml.SafeLoader)\n",
    "PREPROCESSING_PARAMS = yaml.load(open(\"configs/preprocessing.yaml\"), Loader=yaml.SafeLoader)\n",
    "MODEL_NAME = yaml.load(open(\"configs/model.yaml\"), Loader=yaml.SafeLoader)['MODEL_NAME']\n",
    "MODEL_PARAMS = yaml.load(open(\"configs/model.yaml\"), Loader=yaml.SafeLoader)[MODEL_NAME]\n",
    "TRAINING_PARAMS = yaml.load(open(\"configs/training.yaml\"), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =  DATASET_PARAMS['CATEGORIES']\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, DATASET_PARAMS['DATA_PATH'])\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATASET_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_device\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import generate_filenames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames_df = generate_filenames_df(TRAIN_DIR, categories)\n",
    "val_filenames_df = generate_filenames_df(VAL_DIR, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import preprocess\n",
    "\n",
    "target_input_size = tuple(PREPROCESSING_PARAMS['INPUT_SIZE'])\n",
    "train_transform = preprocess(\n",
    "    target_input_size=target_input_size,\n",
    "    rotation_range=PREPROCESSING_PARAMS['ROTATION_RANGE'],\n",
    "    width_shift_range=PREPROCESSING_PARAMS['WIDTH_SHIFT_RANGE'],\n",
    "    height_shift_range=PREPROCESSING_PARAMS['HEIGHT_SHIFT_RANGE'],\n",
    "    brightness_range=PREPROCESSING_PARAMS['BRIGHTNESS_RANGE'],\n",
    "    zoom_range=PREPROCESSING_PARAMS['ZOOM_RANGE'],\n",
    "    horizontal_flip=PREPROCESSING_PARAMS['HORIZONTAL_FLIP'],\n",
    "    vertical_flip=PREPROCESSING_PARAMS['VERTICAL_FLIP'],\n",
    "    channel_shift_range=PREPROCESSING_PARAMS['CHANNEL_SHIFT_RANGE'],\n",
    "    fill_mode=PREPROCESSING_PARAMS['FILL_MODE'],\n",
    "    shear_range=PREPROCESSING_PARAMS['SHEAR_RANGE']\n",
    "    )\n",
    "\n",
    "val_transform = preprocess(target_input_size=target_input_size) # only rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import Loader\n",
    "train_loader = Loader(train_filenames_df, \n",
    "                     batch_size=TRAINING_PARAMS['BATCH_SIZE'], \n",
    "                     num_workers=TRAINING_PARAMS['NUM_WORKERS'], \n",
    "                     transform=train_transform, \n",
    "                     shuffle=TRAINING_PARAMS['SHUFFLE'])\n",
    "\n",
    "val_loader = Loader(val_filenames_df, \n",
    "                    batch_size=TRAINING_PARAMS['BATCH_SIZE'], \n",
    "                    num_workers=TRAINING_PARAMS['NUM_WORKERS'], \n",
    "                    transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientCapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"CAPSNET\":\n",
    "    from src.model import EfficientCapsNet\n",
    "    from src.loss import MarginLoss, marginLoss\n",
    "\n",
    "    model = EfficientCapsNet(input_size=(MODEL_PARAMS['INPUT_SIZE']))\n",
    "    loss = MarginLoss()\n",
    "    # loss = marginLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"DENSENET121\":\n",
    "    from src.densenet import DenseNet121\n",
    "    from torch.nn import CrossEntropyLoss\n",
    "\n",
    "    model = DenseNet121(num_classes=num_classes, dropout_rate=MODEL_PARAMS['DROPOUT_RATE'])\n",
    "    loss = CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=TRAINING_PARAMS['LEARNING_RATE'])\n",
    "\n",
    "# use torcheval metrics\n",
    "# metrics\n",
    "from torcheval.metrics import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from src.metrics import (\n",
    "    MulticlassMCC,\n",
    "    MulticlassSpecificity\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"mcc\": MulticlassMCC(num_classes=num_classes, device=DEVICE),\n",
    "    \"accuracy\": MulticlassAccuracy(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"f1_score\": MulticlassF1Score(num_classes=num_classes, average= TRAINING_PARAMS['AVERAGE'], device=DEVICE),\n",
    "    \"precision\": MulticlassPrecision(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE),\n",
    "    \"recall\": MulticlassRecall(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE),\n",
    "    \"specificity\": MulticlassSpecificity(num_classes=num_classes, average=TRAINING_PARAMS['AVERAGE'], device = DEVICE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuno\\anaconda3\\envs\\xdl-env\\lib\\site-packages\\torcheval\\metrics\\functional\\classification\\accuracy.py:275: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:234.)\n",
      "  num_correct = mask.new_zeros(num_classes).scatter_(0, target, mask, reduce=\"add\")\n"
     ]
    }
   ],
   "source": [
    "from src.train import train\n",
    "\n",
    "history = train(model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    criterion=loss, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=TRAINING_PARAMS['NUM_EPOCHS'], \n",
    "    device=DEVICE,\n",
    "    metrics=metrics,\n",
    "    print_every=TRAINING_PARAMS['PRINT_EVERY'],\n",
    "    save_patience=TRAINING_PARAMS['SAVE_PATIENCE'],\n",
    "    save_path=TRAINING_PARAMS['SAVE_PATH'],\n",
    "    save_model=TRAINING_PARAMS['SAVE_MODEL'],\n",
    "    save_metrics=TRAINING_PARAMS['SAVE_METRICS']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xdl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
